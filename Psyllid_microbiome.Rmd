---
title: "Psyllid_microbiome"
author: "Alexander Piper"
date: "14/08/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
# Knitr global setup - change eval to true to run code

library(knitr)
knitr::opts_chunk$set(echo = TRUE, eval=FALSE, message=FALSE,error=FALSE,fig.show = "hold", fig.keep = "all")
opts_knit$set(root.dir = 'C:/Users/ap0y/Dropbox/workprojects/Agriculture Victoria/Psyllid_microbiome')
setwd("C:/Users/ap0y/Dropbox/workprojects/PHD/Metabarcoding/Psyllid_microbiome")
opts_chunk$set(dev = 'png')
```

# Introduction 

Potential sturcture:
1- Richness - is alpha diversity related to psyllid Identity, or phylogeny
2- Clustering & Beta diversity - CLR /PhilR
3- Random forest - Is whole microbiome predictive of host identity
4- Mantel tests, PGLMM - is whole microbiome related to host phylogeny?
5- Core microbiome (endosymbiont) analysis - Is host phylogeny predicted by phylogeny of certain endosymbionts or core micorbiome members?

## Load packages 

```{r install & Load packages} 
#Set required packages
.cran_packages <- c("ggplot2", "gridExtra", "tidyverse", "scales", "stringdist", "patchwork", "vegan", "ggpubr", "seqinr", "viridis","ape", "data.table", "RColorBrewer")
.bioc_packages <- c("dada2", "phyloseq", "DECIPHER","Biostrings","ShortRead","psadd","microbiome","philr")
#.github_packages <- c("metacal", "taxreturn", "piperline","speedyseq")

#.inst <- .cran_packages %in% installed.packages()
#if(any(!.inst)) {
#   install.packages(.cran_packages[!.inst])
#}
#.inst <- .bioc_packages %in% installed.packages()
#if(any(!.inst)) {
#  if (!requireNamespace("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
#  BiocManager::install(.bioc_packages[!.inst], ask = F)
#}
#
#Load all packages
sapply(c(.cran_packages,.bioc_packages), require, character.only = TRUE)

#Load helper functions 
source('R/helper_functions.R')

#devtools::install_github("benjjneb/dada2")
#devtools::install_github("mikemc/speedyseq")
#devtools::install_github("alexpiper/taxreturn")
#library(taxreturn)

options(stringsAsFactors = FALSE)

```

# Quality Control

## Split files by seqrun
```{r}
samdf <- read.csv("sample_data/sample_info.csv")

run1 <- samdf %>%
  filter(seqrun==1) %>%
  pull(SampleID) %>%
  as.character()
write_lines(run1,path="Run1.txt")

run2 <- samdf %>%
  filter(seqrun==2) %>%
  pull(SampleID) %>%
  as.character()
write_lines(run2,path="Run2.txt")

run3 <- samdf %>%
  filter(seqrun==3) %>%
  pull(SampleID) %>%
  as.character()
write_lines(run3,path="Run3.txt")

```


```{bash split files}

mkdir run_1
cat Run1.txt | while read i; do
payload=$(ls | grep $i)
echo $payload
mv $payload run_1
done

mkdir run_2
cat Run2.txt | while read i; do
payload=$(ls | grep $i)
echo $payload
mv $payload run_2
done

mkdir run_3
cat Run3.txt | while read i; do
payload=$(ls | grep $i)
echo $payload
mv $payload run_3
done

```

## Sequencer IDs for different runs

run_1 - @M01895:3:000000000-AFED3:1:1101:11856:1005 1:N:0:89
run_2 - @M00598:140:000000000-ALTW6:1:1104:15177:9425 2:N:0:120
run_3 - @M00933:9:000000000-BFR4B:1:1101:13542:1780 1:N:0:86


## Sequence quality control

```{r Pooling of libraries}
library(ShortRead)

runs <- dir("data/", pattern="run_")

for (i in seq(along=runs)){
path <- paste0("data/",runs[i]) # CHANGE ME to the directory containing your demultiplexed forward-read fastq files

  #path <- paste0("data/",runs[i])

#Plot number of reads
dat <- as.data.frame(countLines(dirPath=path, pattern=".fastq")) %>%
  rownames_to_column()  %>%
   `colnames<-`(c("Sample", "Reads")) %>%
  filter(str_detect(Sample,"R1"))

#Plot pooling

gg.pooling <- ggplot(data=dat, aes(x=Sample,y=Reads),stat="identity") + 
  geom_bar(aes(fill=Reads),stat="identity")  + 
  scale_fill_viridis(name = "Reads", begin=0.1) + 
  theme(axis.text.x = element_text(angle=90, hjust=1), plot.title=element_text(hjust = 0.5), plot.subtitle =element_text(hjust = 0.5))+ 
  geom_hline(aes(yintercept = mean(Reads)))  +
  xlab("sample name")+
  ylab("Number of reads") + 
  labs(title= paste0("Pooling for : ", runs[i]), subtitle = paste0("Total Reads: ", sum(dat$Reads), " Average reads: ",  sprintf("%.0f",mean(dat$Reads))," Standard deviation: ", sprintf("%.0f",sd(dat$Reads)))) +
  coord_flip()

plot(gg.pooling)
}
```


## Trim primers

DADA2 requires Non-biological nucleotides i.e. primers, adapters, linkers, etc to be removed. Prior to begining this workflow, samples were demultiplexed and illumina adapters were removed by the MiSeq software, however primer sequences still remain in the reads and must be removed prior to use with the DADA2 algorithm.

 Primer sequences - 
16S F CCTACGGGNGGCWGCAG
16S R GACTACHVGGGTATCTAATCC

All reads were trimmed to 300bp, then primers were removed. All reads for which primers were not detected were removed using the maxlength function.

```{r trim primers,message=FALSE}
#Install bbmap
#bbmap_install()

#Problem - maxlength is removing run 2 - Why tf is this over 300bp reads??

#Loop over runs - Maxlength set to remove any untrimmed reads
runs <- dir("data/", pattern="run_")

for (i in seq(along=runs)){
path <- paste0("data/",runs[i]) # CHANGE ME to the directory containing your demultiplexed forward-read fastq files

#Trim forward primers - Set a maxlength to remove all those that werent trimemd
fastqFs <- sort(list.files(path, pattern="_R1", full.names = TRUE))
fastqRs <- sort(list.files(path, pattern="_R2_", full.names = TRUE))

bbtools_trim(install="bin/bbmap", fwd=fastqFs,rev=fastqRs, primers=c("CCTACGGGNGGCWGCAG","GACTACHVGGGTATCTAATCC"), copyundefined=TRUE, outpath="trimmed",ktrim="l", ordered=TRUE,mink=FALSE, hdist=2, overwrite=TRUE, samelength=TRUE, forcetrimright = 300, maxlength = 285)
}

```

## Plot read quality & lengths

Note - something is going wierd with run 3

Run2 reverse, most reads drop off early

Run1 reversse are pretty awful, drop below Q20 at about 200
```{r QA plot, eval = TRUE, cache= TRUE}
runs <- dir("data/", pattern="run_")
readcounts <- vector("list", length=length(runs))

for (i in seq(along=runs)){
 path <- paste0("data/",runs[i],"/trimmed" )# CHANGE ME to the directory containing your demultiplexed forward-read fastq files

  filtFs <- sort(list.files(path, pattern="_R1_", full.names = TRUE))
  filtRs <- sort(list.files(path, pattern="_R2_", full.names = TRUE))
  p1 <- plotQualityProfile(filtFs, aggregate = TRUE) + ggtitle(paste0(runs[i]," Forward Reads")) 
  p2 <- plotQualityProfile(filtRs, aggregate = TRUE) + ggtitle(paste0(runs[i]," Reverse Reads"))
  
  #output plots
  dir.create("output/figures/")
  pdf(paste0("output/figures/",runs[i],"_prefilt_quality.pdf"), width = 11, height = 8 , paper="a4r")
  plot(p1+p2)
  dev.off()
  
  #Get lengths
  readcounts[[i]] <- cbind(width(readFastq(file.path(path, fastqFs))), width(readFastq(file.path(path, fastqRs))))

}
```

The max expected error function is used as the primary quality filter, and all reads containing N bases were removed

In order to reduce the amount of  reverse reads violating the MaxEE filter, the reverse reads were truncated at 200 to remove the quality crash that is typical of illumina sequencers

Total amplicon = 465bp 
Sequencing = 2x300bp = 600bp
Primers = 17bp + 21bp = 38bp
Read overlap = 600 - 465 - 38 = 97bp

reverse should potentiall be reduced further - (from 230 to 200)

```{r filter and trim}
runs <- dir("data/", pattern="run_")
filtered_out <- vector("list", length=length(runs))
readlengths <- vector("list", length=length(runs))

for (i in 1:length(runs)){
  path <- paste0("data/",runs[i],"/trimmed/") # CHANGE ME to the directory containing your demultiplexed forward-read fastq files
  filtpath <- file.path(path, "filtered") # Filtered forward files go into the path/filtered/ subdirectory
  dir.create(filtpath)
  fastqFs <- sort(list.files(path, pattern="R1_001.*"))
  fastqRs <- sort(list.files(path, pattern="R2_001.*"))
  
  if(length(fastqFs) != length(fastqRs)) stop(paste0("Forward and reverse files for ",runs[i]," do not match."))
  
  filtered_out[[i]] <- (filterAndTrim(fwd=file.path(path, fastqFs), filt=file.path(filtpath, fastqFs),
                                      rev=file.path(path, fastqRs), filt.rev=file.path(filtpath, fastqRs),
                                      maxEE=c(2,3),truncQ = 0,truncLen=c(280,200), maxN = 0,  rm.phix=TRUE, compress=TRUE, verbose=TRUE))
  
  # post filtering plot
  filtFs <- sort(list.files(filtpath, pattern="R1_001.*", full.names = TRUE))
  filtRs <- sort(list.files(filtpath, pattern="R2_001.*", full.names = TRUE))
  p1 <- plotQualityProfile(filtFs, aggregate = TRUE) + ggtitle(paste0(runs[i]," Forward Reads")) 
  p2 <- plotQualityProfile(filtRs, aggregate = TRUE) + ggtitle(paste0(runs[i]," Reverse Reads"))
  
  #output plots
  dir.create("output/figures/")
  pdf(paste0("output/figures/",runs[i],"_postfilt_quality.pdf"), width = 11, height = 8 , paper="a4r")
  plot(p1+p2)
  dev.off()
  
  #Get lengths post filter
  readlengths[[i]] <- cbind(width(readFastq(file.path(filtFs))), width(readFastq(file.path(filtRs))))
}
  
print(filtered_out)

```



# Sequence processing

## Infer sequence variants for each run

Every amplicon dataset has a different set of error rates and the DADA2 algorithm makes use of a parametric error model (err) to model this and infer real biological sequence variation from error. Following error model learning, all identical sequencing reads are dereplicated into into “Exact sequence variants” with a corresponding abundance equal to the number of reads with that unique sequence. The forward and reverse reads are then merged together by aligning the denoised forward reads with the reverse-complement of the corresponding reverse reads, and then constructing the merged “contig” sequences. Following this step, a sequence variant table is constructed and saved as an RDS file.

For this analysis we will use all the reads to estimate error rate, and plot the error model for each run as a sanity check

The purpose of priors is to increase sensitivity to a restricted set of sequences, including singleton detection, without increasing false-positives from the unrestricted set of all possible amplicon sequences that must be considered by the naive algorithm

```{r Learn error rates }
runs <- dir("data/", pattern="run_")
set.seed(100)

for (i in seq(along=runs)){
 path <- paste0("data/",runs[i],"/trimmed/" )# CHANGE ME to the directory containing your demultiplexed forward-read fastq files
  filtpath <- file.path(path, "filtered") # Filtered forward files go into the path/filtered/ subdirectory
  
  filtFs <- list.files(filtpath, pattern="R1_001.*", full.names = TRUE)
  filtRs <- list.files(filtpath, pattern="R2_001.*", full.names = TRUE)
  
    # Learn error rates from samples
  # nread tells the function how many reads to use in error learning, this can be increased for more accuracy at the expense of runtime
  
  errF <- learnErrors(filtFs, multithread=TRUE, randomize=TRUE)
  errR <- learnErrors(filtRs, multithread=TRUE, randomize=TRUE)
  
  ##Print error plots to see how well the algorithm modelled the errors in the different runs
  print(plotErrors(errF, nominalQ=TRUE)+ ggtitle(paste0(runs[i]," Forward Reads")))
  print(plotErrors(errR, nominalQ=TRUE)+ ggtitle(paste0(runs[i]," Reverse Reads")))
  
  #Error inference and merger of reads - Using pseudo pooling for increased sensitivity

  dadaFs <- dada(filtFs, err=errF, multithread=TRUE, pool="pseudo")
  dadaRs <- dada(filtRs, err=errR, multithread=TRUE, pool="pseudo")
 
  mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE, minOverlap = 20)
  
# Construct sequence table

seqtab <- makeSequenceTable(mergers)

saveRDS(seqtab, paste0(path,"/seqtab.rds")) # CHANGE ME to where you want sequence table saved
}
```

## Merge Runs, Remove Chimeras

Now that the sequence tables are created for each run, they need to be merged into a larger table representing the entire study. Looking at the length of the sequences, we see some off target amplification. There are 3 large peaks, the first one at 280, second at 402bp, and third at 427. The 427bp peak contains the majority of the sequences and is the expected size, while the 402bp peak contains wolbachia which have a 24bp deletion. We will cut the sequences to between 400 and 450, which should take into account any length variation, and remove the 280bp peak (which is the length of the forward read and most likely artefactual). Following this, chimeric sequences are identified and removed using removeBimeraDenovo


```{r merge runs and remove chimeras}
runs <- dir("data/", pattern="run_")
stlist <- vector()

for (i in seq(along=runs)){
  path <- paste0("data/",runs[i],"/trimmed/" )
  seqs <- list.files(path, pattern="seqtab.rds", full.names = TRUE)
  
  assign(paste("st", i, sep = ""),readRDS(seqs))
  stlist <- append(stlist, paste("st", i, sep = ""), after=length(seqs))
}

st.all <- mergeSequenceTables(st1, st2, st3)

#Test collapsed
#st.all <- collapseNoMismatch(st.all, minOverlap = 20, orderBy = "abundance",
#                                   vec = TRUE, verbose = TRUE)


#Remove chimeras
seqtab.nochim <- removeBimeraDenovo(st.all, method="consensus", multithread=TRUE, verbose=TRUE)

#Check output of chimera removal
print(paste(sum(seqtab.nochim)/sum(st.all),"of the abundance remaining after chimera removal"))

#Check complexity
hist(seqComplexity(seqtab.nochim), 100)


#Look at seqlengths
plot(table(nchar(getSequences(seqtab.nochim))))

backup <- seqtab.nochim

#cut to expected size
seqtab.nochim <- seqtab.nochim[,nchar(colnames(seqtab.nochim)) %in% 400:435]

plot(table(nchar(getSequences(seqtab.nochim))))
print(paste(sum(seqtab.nochim)/sum(st.all),"of the abundance remaining after cutting"))

#Fix names -removing read name, sample number etcc
rownames(seqtab.nochim) <- rownames(seqtab.nochim) %>% 
  str_split_fixed("_",n=Inf) %>%
    as_tibble() %>%
  unite(col=SampleID, c("V1","V2"),sep="_") %>%
  pull(SampleID)

dir.create("output/rds/")
saveRDS(seqtab.nochim, "output/rds/seqtab_final.rds") # CHANGE ME to where you want sequence table saved

```

# Assign taxonomy 



Do a search for carsonella in each of these, and perhaps just do an asignment with the different datasets

We will use the IDTAXA algorithm of Murali et al 2018 - https://doi.org/10.1186/s40168-018-0521-5

This requires training on a curated reference database - The pre-trained file can be found in the reference folder, alternatively see the taxreturn scripts to curate a reference database and train a new classifier.

Folllowing assignment with IDTAXA, we will also use exact matching with a reference database to assign more sequences (including the synthetic positive controls) to species level

### Assign Taxonomy using RDP

```{r assign taxonomy}
seqtab.nochim <- readRDS("output/rds/seqtab_final.rds")

# Assign Kingdom:Genus taxonomy using RDP classifier
tax <- assignTaxonomy(seqtab.nochim, "reference/silva_v132_symbionts_trainset_trimmed.fa.gz", multithread=TRUE, minBoot=60, outputBootstraps=FALSE)
colnames(tax) <- c("Root", "Phylum", "Class", "Order", "Family", "Genus")

##add species to taxtable using exact matching
tax_plus <- addSpecies(tax, "reference/silva_species_assignment_v132.fa.gz", allowMultiple=TRUE)

##join genus and species name in species rank column - need to make this part of addspecies
sptrue <- !is.na(tax_plus[,7])
tax_plus[sptrue,7] <- paste(tax_plus[sptrue,6],tax_plus[sptrue,7], sep=" ")

tax_plus <- propagate_tax(tax_plus,from="Phylum")

#add Genus_SPP
#for(col in seq(7,ncol(tax_plus))) { 
# propagate <- is.na(tax_plus[,col]) & !is.na(tax_plus[,col-1])
#  tax_plus[propagate,col:ncol(tax_plus)] <-  "spp."
#}

#Check Output
taxa.print <- tax_plus # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)


# Write taxonomy table to disk
saveRDS(tax_plus, "output/rds/tax_RDP_final.rds") 
```


##Assign taxonomy with IDTAXA

Do assigntaxonomy with the full length IDTAXA silva databse

then do assign species with the one supplemented with the hall et al etc data

```{r IDTAXA}
seqtab.nochim <- readRDS("output/rds/seqtab_final.rds")

#trainingSet <- readRDS("reference/SILVA_SSU_r132_March2018.RData")
load("C:/Users/ap0y/Dropbox/workprojects/PHD/Metabarcoding/Psyllid_microbiome/reference/SILVA_SSU_r132_March2018.RData")
dna <- DNAStringSet(getSequences(seqtab.nochim)) # Create a DNAStringSet from the ASVs

##Decide on threshold
ids <- IdTaxa(dna, trainingSet, processors=1, threshold = 60, verbose=TRUE)  

#delete existing file
cat("",file="idtaxa.csv")
for (i in 1:length(ids)){
 lines <- as.data.frame(t(cbind(ids[[i]]$taxon,ids[[i]]$confidence)))
 rownames(lines) <- c("taxa","confidence")
write.table(lines,file="idtaxa.csv",sep=",",append=TRUE, col.names=FALSE)
}

ranks <-  c("Kingdom", "Phylum","Class", "Order", "Family", "Genus","Species") # ranks of interest
#Convert the output object of class "Taxa" to a matrix analogous to the output from assignTaxonomy
tax <- t(sapply(ids, function(x) {
        taxa <- x$taxon
        taxa[startsWith(taxa, "unclassified_")] <- NA
        taxa
}))

library(stringi)
tax <- stri_list2matrix(lapply(tax, unlist), byrow=TRUE, fill=NA)

#Add sequences and column names to matrix
colnames(tax) <- ranks; rownames(tax) <- getSequences(seqtab.nochim)

#Subset to remove the root rank
tax <- subset(tax, select=c("Kingdom", "Phylum","Class", "Order", "Family", "Genus","Species"))

#Propagate high order ranks to unassigned ASV's
tax <- propagate_tax(tax,from="Phylum") 


#Check Output
taxa.print <- tax # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)

# Write taxonomy table to disk
saveRDS(tax, "tax_IdTaxa.rds") 

#tax <- readRDS("output/rds/tax_IdTaxa.rds") 

#Add missed species using exact matching

#
exact <- assignSpecies(seqtab.nochim, "reference/silva_v132_symbionts_species.fa.gz", allowMultiple = TRUE, tryRC = TRUE,
  n = 100, verbose = FALSE)

exact <- exact %>% 
  as.tibble() %>%
  mutate(binomial =  case_when(!is.na(Species) ~  paste0(Genus,"_",Species)))


exact <- exact %>% 
  as_tibble() %>%
  mutate(binomial =  case_when(!is.na(Species) ~  paste0(Genus,"_",Species)))


#merge together
#For exact where Species is not NA, replace tax$Species where Species contains K__,P__,C__,O__,F__,G__
pattern <- c("K__","P__","C__","O__","F__","G__")
for (row in 1:nrow(tax)){
  if   (str_detect(tax[row,7], paste(pattern, collapse="|")) && !is.na(exact$binomial[row]) == TRUE ) {
  tax[row,7] <- exact$binomial[row]
  }
}

# Write taxonomy table to disk
saveRDS(tax, "tax_IdTaxaExact.rds") 

```

## Create phylogenetic tree

```{r phylogenetic tree}
seqtab.nochim <- readRDS("output/rds/seqtab_final.rds")

seqs <- getSequences(seqtab.nochim)
names(seqs) <- seqs # This propagates to the tip labels of the tree
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA)

library(phangorn)
phang.align <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phang.align)
treeNJ <- NJ(dm) # Note, tip order != sequence order
fit = pml(treeNJ, data=phang.align)

## negative edges length changed to 0!

fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
                      rearrangement = "stochastic", control = pml.control(trace = 0))
detach("package:phangorn", unload=TRUE)

# Write taxonomy table to disk
saveRDS(fitGTR, "output/rds/phytree.rds") 

```

# Analysis

## Make Phyloseq object

Following taxonomic assignment, the sequence table and taxonomic table are merged into a single phyloseq object alongside the sample info csv.

We then make a plot to evaluate the effectiveness of taxonomic assignment to each rank

```{r create PS, eval = FALSE}
seqtab.nochim <- readRDS("output/rds/seqtab_final.rds")
tax_plus <- readRDS("output/rds/tax_RDP_final.rds") 
fitGTR <- readRDS("output/rds/phytree.rds") 

#Load sample information
## ---- samdat ----
samdf <- read.csv("sample_data/Sample_info.csv", header=TRUE) 
samdf <- samdf %>%
  dplyr::filter(!duplicated(SampleID)) %>%
  mutate(replicated = Sample.Name %in% ( samdf %>% group_by(Sample.Name) %>% # Flag replicated samples
                                           filter(n()>1) %>% 
                                           pull(Sample.Name))) %>%
  set_rownames(.$SampleID) %>%
  dplyr::select(c("SampleID", "Sample.Name", "seqrun", "psyllid_spp", "psyllid_genus", "psyllid_family", "hostplant_spp","Collection.Date","replicated")) #Collection

#Display samDF
head(samdf)

## ---- phyloseq ----
ps <- phyloseq(tax_table(tax_plus), sample_data(samdf),
               otu_table(seqtab.nochim, taxa_are_rows = FALSE),
               phy_tree(fitGTR$tree))

if(nrow(seqtab.nochim) > nrow(sample_data(ps))){warning("Warning: All samples not included in phyloseq object, check sample names match the sample metadata")}

##save phyloseq object
saveRDS(ps, "output/rds/ps_rdp.rds")

#Output tables of results
dir.create("output/csv")
dir.create("output/csv/unfiltered/")

##Export raw csv
speedyseq::psmelt(ps) %>%
  write.csv(file = "output/csv/rawdata.csv")

#Summary export
summarize_taxa(ps, "Species", "SampleID") %>%
  spread(key="SampleID", value="totalRA") %>%
  write.csv(file = "output/csv/unfiltered/spp_sum.csv")

summarize_taxa(ps, "Genus", "SampleID") %>%
  spread(key="SampleID", value="totalRA") %>%
  write.csv(file = "output/csv/unfiltered/gen_sum.csv")
```

### Summarise taxonomic assignment

```{r sum taxa}
#Fraction of reads assigned to each taxonomic rank
sum_reads <- speedyseq::psmelt(ps) %>%
  gather("Rank","Name",rank_names(ps)) %>%
  group_by(Rank) %>% 
  mutate(Name = replace(Name, str_detect(Name, "__"),NA)) %>% # This line turns the "__" we added to lower ranks back to NA's
  summarize(Reads_classified = sum(Abundance * !is.na(Name))) %>%
  mutate(Frac_reads = Reads_classified / sum(sample_sums(ps))) %>%
  mutate(Rank = factor(Rank, rank_names(ps))) %>%
  arrange(Rank)

#Fraction of ASV's assigned to each taxonomic rank
sum_otu <- tax_table(ps) %>%
  as("matrix") %>%
  as_tibble(rownames="OTU") %>%
  gather("Rank","Name",rank_names(ps)) %>%
  group_by(Rank) %>%
  mutate(Name = replace(Name, str_detect(Name, "__"),NA)) %>% # This line turns the "__" we added to lower ranks back to NA's
  summarize(OTUs_classified = sum(!is.na(Name))) %>%
  mutate(Frac_OTUs = OTUs_classified / ntaxa(ps)) %>%
  mutate(Rank = factor(Rank, rank_names(ps))) %>%
  arrange(Rank)

print(sum_reads)
print(sum_otu)
```


## Detect and remove outlier Samples

Detecting and potentially removing samples outliers (those samples with underlying data that do not conform to experimental or biological expectations) can be useful for minimizing technical variance. This can be caused by a number of reasons, including low-reads assigned to that sample. In this case we remove all samples below 1000 reads, as these include all samples contributing to lower than usual ASV counts.

```{r sample-removal-identification}
## Remove mocks
rm_mocks <- c("mockA_S51", "MockEven_S193", "Mock_S192", "PCRctrl_S191", "MockStaggered_S194", "PCRctrl_S191", "91_S167")
nsamples(ps)
ps0 <- ps %>% subset_samples(!sample_names(ps) %in% rm_mocks) %>% #Remove mocks
       
        filter_taxa(function(x) mean(x) > 0, TRUE) #Drop missing taxa from table 
nsamples(ps0)

# Format a data table to combine sample summary data with sample variable data
ss.df <- merge(as.data.frame(sample_data(ps0)), data.frame("ASV" = sample_sums(ps0)), by ="row.names")

# Plot Count of ASVs and read s
threshold = 1000

gg.asv.boxplot <- merge(as.data.frame(sample_data(ps0)), data.frame("Reads" = sample_sums(ps0)), by ="row.names") %>%
  ggplot( aes(x= Sample.Name, y = Reads, color = Sample.Name, shape=replicated)) + 
  geom_boxplot(outlier.colour="RED", position = position_dodge(width = 0.8)) +
  geom_jitter(size = 2, alpha = 0.6) +
  scale_y_log10() +
  geom_hline(yintercept = threshold, lty = 2) +
  theme(legend.position = "none",
        axis.text.x = element_text(angle=90, vjust=1))

print(gg.asv.boxplot)
## Plot richness

gg.rich <- plot_richness(ps0, measures="Observed")
print(gg.rich)

#Remove all samples under the minimum read threshold 
ps1 <- prune_samples(sample_sums(ps0)>=threshold, ps0) # 
ps1 <- filter_taxa(ps1, function(x) mean(x) > 0, TRUE) #Drop missing taxa from table
print(paste(nsamples(ps) - nsamples(ps1), " Samples and ", ntaxa(ps) - ntaxa(ps1), " taxa Dropped"))

```


## Process Replicates

### Compare reproducibilty of replicates

Rarefaction curves are useful	to	assess	sensitivity	of	sample	size	to	observed	alpha-diversity estimates.
```{r replicate reproducibility}
#Subset to replicated samples
ps.reps <- subset_samples(ps1, replicated == TRUE)

#Plot read differences between replicates
gg.reps <- plot_bar(ps.reps, x="Sample", y="Abundance", fill="Phylum") +
  facet_grid(~Sample.Name, drop=TRUE, scales="free_x") +
  geom_hline(yintercept=1000)

#Plot rarefaction curve
rarecurve(otu_table(ps.reps), step=50, cex=0.5)

#Rarefy replicates to same read depth
nspec <- specnumber(otu_table(ps.reps)) # observed number of species
raremax <- min(rowSums(otu_table(ps.reps)))
rare <- rrarefy(otu_table(ps.reps),raremax)

#PCA of rarefied samples
raredist <- vegan::vegdist(rare, method="euclidean")

r.pcx <- prcomp(raredist)

pc_samp <- data.frame(SampleID = rownames(r.pcx$x), r.pcx$x[, 1:2])%>%
  left_join(samdf, by="SampleID")
pc_otu <- data.frame(OTU = rownames(r.pcx$rotation), r.pcx$rotation[, 1:2])

# calculate percent variance explained for the axis labels
pc1 <- round(r.pcx$sdev[1]^2/sum(r.pcx$sdev^2),2)
pc2 <- round(r.pcx$sdev[2]^2/sum(r.pcx$sdev^2),2)
pc_xlab <- paste("PC1: ", pc1, sep="")
pc_ylab <- paste("PC2: ", pc2, sep="")

library(ggplot2)
gg.reps <- ggplot(data=pc_samp, aes(x=PC1, y=PC2, colour=SampleID, label=SampleID)) + 
  geom_point(alpha=0.5, size=3) +
  geom_text() +
  #geom_point(data=pc_otu,aes(PC1, PC2)) +
  theme_bw() + 
  geom_hline(yintercept = 0, linetype=2) +  
  geom_vline(xintercept = 0, linetype=2) +
  xlab(pc_xlab) + 
  ylab(pc_ylab) +
  theme(legend.position = "none")+
  coord_fixed(ratio=pc2/pc1) # Scale plot by variance explained

print(gg.reps)
```

### Merge technical replicates

With only 16 samples replicated, and only on the first 2 sequencing runs i dont think there is a way to explicitly take into account replicate variability, therefore all replicates were merged

```{r replicates}
# Merge replicates
ps.merged <- ps1 %>%
    merge_samples(group = "Sample.Name")

#This loses the sample metadata - Need to add it agian
samdf <- read.csv("sample_data/Sample_info.csv", header=TRUE) %>%
  filter(!duplicated(Sample.Name)) %>%
  set_rownames(.$Sample.Name) %>%
  dplyr::select(c("SampleID", "Sample.Name", "seqrun", "psyllid_spp", "psyllid_genus", "psyllid_family", "hostplant_spp","Collection","Collection.Date"))

sample_data(ps.merged) <- samdf
ps.merged <- filter_taxa(ps.merged, function(x) mean(x) > 0, TRUE) #Drop missing taxa from table
```


## Taxon Filtering

The following R chunk removes taxa not-typically part of a bacterial microbiome analysis.

We also remove all taxa contained within the blank sample from other samples

```{r taxon-cleaning}
get_taxa_unique(ps.merged, "Root")
get_taxa_unique(ps.merged, "Class")

ps.merged # Check the number of taxa prior to removal
ps2 <- ps.merged %>%
  subset_taxa(
    Root == "Bacteria" & #This is probably the only required one
    Family  != "mitochondria" &
    Class   != "Chloroplast" &
    Phylum != "Cyanobacteria/Chloroplast"
  )
ps2 # Confirm that the taxa were removed
get_taxa_unique(ps2, "Phylum")
get_taxa_unique(ps2, "Class")

```

## Prevalence assesment

Identification of taxa that are poorly represented in an unsupervised manner can identify taxa that will have little to no effect on downstream analysis. Sufficient removal of these "low prevalance" features can enhance many analysis by focusing statistical testing on taxa common throughout the data. However, for our dataset the problem with prevalence filtering for our dataset is that we dont have many replicates of each psyllid species, and therefore there are some high abundance but low prevalence ASV's we dont want to lose.


```{r prevalence-assessment}
# Calculate taxon prevalence across the data set
prevdf <- apply(X = otu_table(ps2),MARGIN = ifelse(taxa_are_rows(ps2), yes = 1, no = 2),FUN = function(x){sum(x > 0)})

# Add taxonomy and total read counts to prevdf - change this to tidyverse code
prevdf <- data.frame(Prevalence = prevdf, TotalAbundance = taxa_sums(ps2), tax_table(ps2))

#Prevalence plot
gg.prev <- subset(prevdf, Phylum %in% get_taxa_unique(ps0, "Phylum")) %>%
  ggplot(aes(TotalAbundance, Prevalence / nsamples(ps2),color=Genus)) +
  geom_point(size = 3, alpha = 0.7) +
  scale_x_log10() +
  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) +
  theme(legend.position="none") +
  ggtitle("Phylum Prevalence in All Samples\nColored by Family")

gg.prev
```

# Alpha Diversity

Instead of using traditional plug-in diversity estiamtors, which only tell us about the diversity of our samples (observed richness), instead of the actual environment (actual richness), we will use the breakaway package which uses biological replicates to estimate the total diversity in the environment. Breakaway estimates the number of missing species based on the sequence depth and  number of rare taxa in the data, and accounts for experimental noise such as the correlation between observed richness and the sequencing depth.

Following the initial estimate of diversity and variance using the breakaway package, we use the betta model of Willis, A. and Bunge, J. (2015) which works like regression but takes into account uncertainty in diversirty estimates betta accounts for strains that are present in the environment but not observed in the samples due to incomplete sampling.. Some of the samples in the initial estimates had large standard errors, indicating that we cannot precisely estimate the total species richness in those sample. In the betta model these samples will be given less weight in the regression than samples with small standard errors on their richness estimates. This is the behaviour we want, because while that sample contains some information, the standard error is telling us that the richness estimate may not be as reliable as other samples' estimates, and we should downweight the importance of that observation relative to observations would smaller standard errors on their richness estimates.

## Association of richness with phylogeny

May be interesting to model richness at different taxonomic ranks?

Psyllid_spp and hostplant_spp are multi-colinear, therefore they cant be included as either additive effects or interaction effects, as it causes the design-matrix to have less than full rank, which means it isn't invertible, and therefore least-squares-techniques fail

This is a univariate phylogenetic analysis, and could be done with the package phylosignal, or a phylogenetic linear mixed model

The effects of phylogenetic signal, defined as “a tendency for related species to resemble each other more than they resemble species drawn at random from the tree” (74), on univariate traits (e.g., microbial alpha diversity) have been examined in parallel with phylosymbiosis studies. Phylogenetic signal indices like Pagel’s λ (75), and Blomberg’s K (76) are based on a random Brownian model of trait evolution (77), These can be calculated with with the phylosignal package

```{r estimate richness}
library(breakaway)

#Model richness for all samples by psyllid spp

ba <- breakaway(ps2)

## Check the specification of the model
betta_pic(summary(ba)$estimate, summary(ba)$error)

ba_estimates <- summary(ba) %>%
      add_column("Sample.Name" = ps2 %>% otu_table %>% sample_names) %>%
      left_join(samdf, by = "Sample.Name")

## Plot the richness estimates from each sample
col <- colorRampPalette(brewer.pal(11, "Spectral"))(75)
gg.barichnes <- ggplot(ba_estimates, aes(x=psyllid_spp, y=estimate, fill=psyllid_spp)) + 
  geom_boxplot(outlier.alpha = 0) +
  geom_jitter(aes(colour=psyllid_spp), colour="black", pch=21) +
  theme_bw() +
  theme(axis.text.x = element_text(angle=90, vjust=0, hjust=1),
        legend.position = "none") +
  scale_fill_manual(values=col) +
  scale_colour_manual(values=col) +
  ylab("Richness Estimate")


#Model richness with psyllid_spp as a fixed effect
bt_spp <- betta(chats = ba_estimates$estimate,
                      ses = ba_estimates$error,
                      X = model.matrix(~psyllid_spp, data = ba_estimates)) 

bt_spp$table

bt_sppdf <- as_tibble(bt_spp$table, rownames="psyllid_spp")%>% 
                mutate_at(2:4, as.numeric) %>%
              magrittr::set_colnames(c("Estimates", "SE", "P"))

## Model with psyllid_spp as a fixed effect and seqrun as a random effect
bt_sppfixed_hostrandom <- betta_random(chats = ba_estimates$estimate,
                                  ses = ba_estimates$error,
                                  X = model.matrix(~psyllid_spp, data = ba_estimates), # Set fixed effects
                                  groups=ba_estimates$seqrun) # Set random effects


bt_randomdf <- as_tibble(bt_sppfixed_hostrandom$table, rownames="psyllid_spp")%>% 
                mutate(psyllid_spp = str_replace(psyllid_spp, pattern="psyllid_spp", replacement="")) %>%
                magrittr::set_colnames(c("psyllid_spp", "Estimates", "SE", "P")) %>%
                mutate(Estimates = case_when(
                  psyllid_spp == "(Intercept)" ~ Estimates,
                  !psyllid_spp == "(Intercept)" ~ Estimates + 
                                      filter(., str_detect(psyllid_spp, "Intercept") ) %>% # Rescale by intercept
                                      pull(Estimates)
                  
                )) %>%
                mutate(psyllid_spp = str_replace_all(psyllid_spp, pattern="\\(Intercept\\)", replacement =
                                                   unique(ba_estimates$psyllid_spp[which(!ba_estimates$psyllid_spp %in% .$psyllid_spp)])
                                                 )) %>%
                mutate(significant = case_when(
                  P < 0.05 ~ TRUE,
                  P > 0.05 ~ FALSE
                ))
#Our intercept term is one that is left out
intercept <- unique(ba_estimates$psyllid_spp[which(!ba_estimates$psyllid_spp %in% bt_randomdf$psyllid_spp)])

## Plotting - arrange by tree
psyllid_tree <- read.tree(text=readLines("sample_data/psyllid_beast_tree.nwk"))

# Match names with alpha diversity
psyllid_tree$tip.label <- psyllid_tree$tip.label %>%
  str_replace_all(pattern="\\.", replacement=" ") %>%
  str_replace_all(pattern="sp^", replacement="sp. ") %>%
  str_replace_all(pattern="POLLENISLAND", replacement="POLLEN ISLAND") %>%
  str_replace_all(pattern="Ctenarytaina fuchsiae$", replacement="Ctenarytaina fuchsia A") %>%
  str_replace_all(pattern="Ctenarytaina fuchsiaeB", replacement="Ctenarytaina fuchsia B") %>%
  str_replace_all(pattern="Ctenarytaina fuchsiaeC", replacement="Ctenarytaina fuchsia C") %>%
  str_replace_all(pattern="Ctenarytaina clavata", replacement="Ctenarytaina clavata sp. ") %>%
  str_replace_all(pattern="Ctenarytaina clavata sp. $", replacement="Ctenarytaina clavata sp. A") %>%
  str_replace_all(pattern="Ctenarytaina sp", replacement="Ctenarytaina sp. ") %>%
  str_replace_all(pattern="carmichaeliae", replacement="carmichaeliae ") %>%
  str_replace_all(pattern="Psylla apicalis", replacement="Psylla apicalis ") %>% # Should these be A,B or?
  str_replace_all(pattern="Trioza sp", replacement="Trioza sp. ") %>%
  str_replace_all(pattern="BRENDAMAY", replacement="BRENDA MAY") %>%
  str_replace_all(pattern="PRICES", replacement="PRICE'S VALLEY") %>%
  trimws(which="right")

psyllid_tree$tip.label[!psyllid_tree$tip.label %in% bt_randomdf$psyllid_spp]

pruned.tree <- drop.tip(psy.tree, psy.tree$tip.label[!psy.tree$tip.label %in% bt_randomdf$psyllid_spp] )

# Plot tree
library(ggtree)
p <- ggtree(pruned.tree, branch.length = "none") + geom_tiplab() + geom_nodelab(geom='label') +
    scale_x_continuous(expand=c(0, 2))

col <- colorRampPalette(brewer.pal(11, "Spectral"))(75)

gg.betarichness <- ggplot(bt_randomdf %>% mutate(psyllid_spp = factor(psyllid_spp, levels=pruned.tree$tip.label)), aes(x=psyllid_spp, y=Estimates, fill=psyllid_spp)) + 
  geom_point(aes(shape=significant, colour=psyllid_spp), size=3) + 
  geom_errorbar(aes(x=psyllid_spp, ymin=Estimates-SE, ymax=Estimates+SE)) +
  geom_hline(yintercept= bt_randomdf %>% filter(psyllid_spp == paste0("(",intercept,")") ) %>% pull(Estimates)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle=90, vjust=0, hjust=1),
        legend.position = "none") +
  scale_fill_manual(values=col) +
  scale_colour_manual(values=col) +
  ylab("Richness Estimate") + 
  coord_flip()  + 
  ggtitle("Estimated taxonomic richness of psyllid microbiomes")

library(patchwork)

p + gg.betarichness

# Plot tree + metadata

bar <- bt_randomdf %>%
  ungroup() %>%
  mutate(id = psyllid_spp) 

p2 <- facet_plot(p, 'Unique Species', data = bar, geom=ggstance::geom_barh,
                 mapping=aes(x=Estimates, fill=significant), stat="identity") +
                theme_bw() +
                scale_fill_manual(values =c("#FC4E07", "#E7B800", "#00AFBB"))

# Add Statistics
library(phylosignal)


#alpha diversity data
dat <- list()
dat$alpha <-  bt_randomdf %>%
  filter(psyllid_spp %in% pruned.tree$tip.label) %>%
  arrange(match(psyllid_spp, pruned.tree$tip.label)) %>%
  pull(Estimates)
dat$random <- rnorm(length(dat$alpha), sd = 10) # NEgative control
dat$bm <- rTraitCont(pruned.tree) #Brownian motion - Positive control
dat <- as.data.frame(dat)

# Make phylosignal object
p4d <- phylo4d(pruned.tree, dat)

#Plot traits
barplot.phylo4d(p4d, tree.type = "phylo", tree.ladderize = TRUE)

#Measure phylogenetic signal
phyloSignal(p4d = p4d, method = "all")

# Asses modelbehavior
phylosim <- phyloSim(tree = pruned.tree, method = "all", nsim = 100, reps = 99)
plot.phylosim(phylosim, what = "pval", stacked.methods = TRUE)

# Lambda is behaving real weird - ignore it

```


# Beta diversity


## philR transformation

To find the Aitchison distance a centered log-ratio (clr) transformation was performed on ASV count data with the R
165 package CoDaSeq (30) before computing the Euclidean distance between samples with
the R package vegan (31). The Aitchison distance was then used in Permutational Multivariate Analyses of Variance (PERMANOVA, 999 permutations) with the vegan function adonis to test whether community composition was significantly different

Many analysis in community ecology and hypothesis testing benefit from data transformation. Many microbiome data sets do not fit to a normal distribution, but transforming them towards normality may enable more appropriate data for specific statistical tests. 

philr phylogenetic transform is based on balances (binary partitions) along an evolutionary tree (Silverman et al., 2017) that is a replacement for the familiar UniFrac distance metric. Distances determined by phylogenetic transforms have the advantage that the binary partitions chosen have a simple interpretation and the correlation structure of the data is fully accounted for. However, the disadvantage is that only the relationships between the chosen partitions can be examined.# Figure 1: Community composition analysis

```{r Philr transfomration}
ps.coda <- ps2
#Rename taxa
taxa_names(ps.coda) <- paste0("SV", seq(ntaxa(ps.coda)),"-",tax_table(ps.coda)[,6])

ps2.philr <- transform_sample_counts(ps.coda, function(x) x+1)

ape::is.rooted(phy_tree(ps2.philr))
ape::is.binary.tree(phy_tree(ps2.philr))

phy_tree(ps2.philr) <- multi2di(phy_tree(ps2.philr))
phy_tree(ps2.philr) <- makeNodeLabel(phy_tree(ps2.philr), method="number", prefix='n')

#Transpose
otu.table <- otu_table(ps2.philr)
tree <- phy_tree(ps2.philr)
metadata <- as(sample_data(ps2.philr), "data.frame")
tax <- tax_table(ps2.philr)
gp.philr <- philr(otu.table, tree,
                  part.weights='enorm.x.gm.counts',
                  ilr.weights='blw.sqrt')

gp.dist <- dist(gp.philr, method="euclidean")

```

#### CLR transformation

Need to decide whether to go with the CLR (easily interpretable) or philr (takes into account phylogenetic structure of microbial com)



```{r}
library(compositions)
library(zCompositions)
library(CoDaSeq)

ps.coda <- ps2
taxa_names(ps.coda) <- paste0("SV", seq(ntaxa(ps.coda)),"-",tax_table(ps.coda)[,6])

#Replace zero values
ps.coda <- transform_sample_counts(ps.coda, function(x) x+1) # Check how much is explained by the pseudocount

f <- t(abundances(ps.coda))
#f.0 <- cmultRepl(f, method="CZM")
f.0 <- f
f.clr <- codaSeq.clr(f.0)
#perb.all <- perb(f.0, ivar="iqlr")

clr.dist <- dist(f.clr, method="euclidean")


```

# Mantel tests

```{r}
#Read in genetic distance
phylo.dist <- read_csv("sample_data/genetic_distance.csv") %>%
  column_to_rownames("SampleID") 

#Make pairwise 
phylo.dist[upper.tri(phylo.dist)] <- 0
phylo.dist <- phylo.dist + t(phylo.dist)
phylo.dist[is.na(phylo.dist)] <- 0

#Rename cols and transform to dist
phylo.dist <- phylo.dist %>%
  set_colnames(rownames(.) %>% str_replace(pattern="\\_S(.*)$",replacement="") %>% make.unique()) %>%
  rownames_to_column("SampleID") %>%
  mutate(SampleID = SampleID %>% str_replace(pattern="\\_S(.*)$",replacement="") %>% make.unique()) %>%
  filter(SampleID %in% rownames(as.matrix(gp.dist))) %>%
  arrange(match(SampleID, colnames(as.matrix(gp.dist)))) %>%
  column_to_rownames("SampleID") %>%
  dplyr::select(one_of(colnames(as.matrix(gp.dist)))) %>%
  as.dist()

#check whats missing
colnames(as.matrix(gp.dist))[which(!colnames(as.matrix(gp.dist)) %in% colnames(as.matrix(phylo.dist)))]

# Microbial community dist
comm.dist <- gp.dist %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column("SampleID") %>%
  filter(SampleID %in% rownames(as.matrix(phylo.dist))) %>%
  dplyr::select(one_of(colnames(as.matrix(phylo.dist)))) %>%
  as.dist()

# Hostplant dist
plant.dist <- read_csv("sample_data/plant_distance.csv") %>%
  select(-one_of("X1", "Host plants")) %>%
  column_to_rownames("SampleID") %>%
  set_colnames(rownames(.) %>% str_replace(pattern="\\_S(.*)$",replacement="") %>% make.unique()) %>%
  rownames_to_column("SampleID") %>%
  mutate(SampleID = SampleID %>% str_replace(pattern="\\_S(.*)$",replacement="") %>% make.unique()) %>%
  filter(SampleID %in% rownames(as.matrix(gp.dist))) %>%
  arrange(match(SampleID, colnames(as.matrix(gp.dist)))) %>%
  column_to_rownames("SampleID") %>%
  dplyr::select(one_of(colnames(as.matrix(gp.dist)))) %>%
  as.dist()

# Spatial dist


#Mantel test - Phylo
plot(comm.dist~phylo.dist)
mantel(comm.dist, phylo.dist)

#Mantel test - Plant
plot(comm.dist~plant.dist)
mantel(comm.dist, plant.dist)

#Mantel test - Spatial
plot(comm.dist~c(spatDistD+1), log="x")
mantel(comm.dist, spatDistD)

#Partial Mantel test - Phylo ~ Plant
mantel.partial(comm.dist, phylo.dist, plant.dist)

#Partial Mantel test - Plant ~ Phylo
mantel.partial(comm.dist, plant.dist, phylo.dist)

#Partial Mantel test - Phylo ~ Space

#Partial Mantel test - Space ~ Phylo

#Partial Mantel test - Plant ~ Space

mantel.partial(comm.dist, spatDistD, phylo.dist)
mantel.partial(comm.dist, log(spatDistD+1), phylo.dist) ##Log distance not better

mantel.partial(comm.dist, phylo.dist, spatDistD)


## CORE TESTS - all those above neutral model expectation



    
```


Dendrogram and bar plots
```{r dendbar}
library(ggdendro)
library(dendextend)

#PhilR dist
hc <- hclust(gp.dist, method="ward.D2")

#CLR
#hc <- hclust(clr.dist, method="ward.D2")

dend <- as.dendrogram(hc)

#Replace labels
samdf <- samdf %>%
  mutate(labels = paste0(psyllid_spp,"-",Sample.Name,"-",hostplant_spp))

lab <- as.data.frame(labels(dend)) %>%
    dplyr::rename(Sample.Name = `labels(dend)`) %>%
    left_join(samdf, by="Sample.Name") %>%
    pull(labels)

labels(dend) <- lab

# Rectangular lines
ddata <- dendro_data(dend, type = "rectangle")
gg.dend <- ggplot(segment(ddata)) + 
  geom_segment(aes(x = x, y = y, xend = xend, yend = yend))  + 
  scale_y_reverse(expand = c(0, 0)) +
  theme_void()+
  scale_x_discrete(expand=c(0.001,0.001))+
  coord_flip()

ps2_bar <- #subset_taxa(ps2, !Family == "Enterobacteriaceae") %>%
            ps2 %>%
  speedyseq::tax_glom(taxrank = "Order") %>%           # agglomerate at Order level
  transform_sample_counts(function(x) {x/sum(x)} ) %>% # Transform to rel. abundance
  speedyseq::psmelt() %>%
  #mutate(Family = case_when(
  #  Abundance >= 0.01 ~ Genus, # Change this to whatever taxrank we want
  #  Abundance < 0.01 ~ "NA"
  #  )) %>%
  #mutate(plot_level = case_when(
  #  Family == "Enterobacteriaceae" | Genus == "Candidatus_Carsonella" ~ paste0("G-",Genus),
  #  TRUE  ~ paste0("P-", Phylum),
  #  )) %>%
  #filter(Abundance > 0.01) %>% # Could instead mutate this to just be "Low abundance"
  mutate(labels = paste0(psyllid_spp,"-",Sample.Name,"-",hostplant_spp)) %>%
  mutate(labels = factor(labels, levels=labels(dend)))

library(RColorBrewer)
col <- colorRampPalette(brewer.pal(11, "Spectral"))(142)

gg.bar <- ggplot(ps2_bar, aes(x = labels, y = Abundance, fill = Order)) + 
  geom_bar(stat = "identity", width = 0.8) +
  theme_minimal()+
  theme(axis.title = element_blank(),
        axis.ticks = element_blank(),
        legend.position = "right",
        plot.margin=unit(c(-2,-1,10,0),unit="cm")) +
  scale_x_discrete(expand=c(0,0),position="top")+
  scale_y_discrete(expand=c(0,0))+
  scale_fill_manual(values=col) +
  guides(fill=guide_legend(ncol=1)) +
  coord_flip() 

#plot together

Fig1 <- gg.dend + gg.bar + plot_layout(ncol = 2, widths = c(1,3)) + plot_annotation(title="Microbial diversity of New Zealand psyllids", subtitle="Run1 & Run3 0.01% threshold, Run 2 0.035% filtering threshold. PhilR transformation, Ward d2 Heirarchial clustering", tag_levels="A")

```

## Can microbiome predict phylogeny

Mantel test

```{r get spatial distance}

# Bespoke function to convert a degree minute second coordinate into a fully numeric one,assuming ° is used for degree sign

convert<-function(coord){
   t1 <- strsplit(coord, "°")
  td <- as.numeric(unlist(lapply(t1, "[", 1)))
  min <- as.numeric(unlist(sapply(strsplit(unlist(lapply(t1, "[",2)),"'"), "[", 1)))
  
  if(nchar(lapply(t1,"[", 2))==10){
    sec <- as.numeric(substr(unlist(sapply(strsplit(unlist(lapply(t1,"[", 2)),"'"), "[", 2)),1,5))
  
  } else  if(nchar(lapply(t1,"[", 2))==9){
    sec <- as.numeric(substr(unlist(sapply(strsplit(unlist(lapply(t1,"[", 2)),"'"), "[", 2)),1,4))
  }
  return(td+min/60+sec/(60*60))
}



  test <- samdf %>%
    separate(Collection, into= c("South", "East"), sep=" ", remove = FALSE) %>%
    mutate(South = na_if(South, "")) %>%
    mutate(South = case_when(
      !is.na(South) ~  convert(South),
      #is.na(South) ~ NA
    ))
  
  for (i in 1:length(test$South)){
    
    if(!is.na(South[i])){test$NEW[i] <- (char2dms(test$South[i], chd=chd,chm=chm,chs=chs))}
  print(i)
    }
  
               str_replace(chm, "") %>%
             str_replace(chs, "") %>%
             str_replace(chd, ".") )
  
    mutate(South = convert(South)) #%>%
    mutate(East = convert(East))
  
South <- convert(unlist(lapply(strsplit(samdf$Collection," "),
                                   "[", 1)))
envData$E <- convert(unlist(lapply(strsplit(samdf$Location," "),
                                   "[", 2)))

#Create a spatial distance between all samples
spatDist <- spDists(cbind(envData$E,envData$S)[!is.na(envData$E),],
                    longlat=TRUE)
rownames(spatDist) <- colnames(spatDist) <-
  envData$ID[!is.na(envData$E)]

```



```{r Ordination}

# perform a singular value decomposition of CLR
f.pcx <- prcomp(gp.philr)
pcx <- f.pcx 

#Name balances

pcnames <-  sapply(rownames(pcx$rotation), function(x) name.balance(tree, tax, x))
pcnames <- make.unique(pcnames, sep = ".")

rownames(pcx$rotation) <- pcnames
#fviz_pca_biplot(pcx) 

#Extract biplot objects
pc_samp <- data.frame(Sample.Name = rownames(pcx$x), pcx$x[, 1:2]) %>%
  left_join(samdf, by="Sample.Name")
pc_otu <- data.frame(OTU = rownames(pcx$rotation), pcx$rotation[, 1:2])

# calculate percent variance explained for the axis labels
pc1 <- round(pcx$sdev[1]^2/sum(pcx$sdev^2),2)
pc2 <- round(pcx$sdev[2]^2/sum(pcx$sdev^2),2)
pc_xlab <- paste("PC1: ", pc1, sep="")
pc_ylab <- paste("PC2: ", pc2, sep="")

library(ggplot2)
gg.biplot <- ggplot(pc_samp, aes(PC1, PC2, label=psyllid_spp, colour=psyllid_spp)) + 
  geom_point(alpha=0.5, size=3) +
  #geom_text(size=3) +
  #geom_segment(data=pc_otu, aes(PC1, PC2, xend=0, yend=0), col="red") +
  #geom_text(data=pc_otu, aes(PC1, PC2, label=OTU), col="red") +
  geom_point(data=pc_otu,aes(PC1, PC2, label=OTU), col="red") +
  theme_bw() + 
  geom_hline(yintercept = 0, linetype=2) +  
  geom_vline(xintercept = 0, linetype=2) +
  xlab(pc_xlab) + 
  ylab(pc_ylab) +
  theme(legend.position = "none")# +
 # coord_fixed(ratio=pc2/pc1) # Scale plot by variance explained

#Plot just OTU loadings

gg.loadings <- ggplot(pc_otu, aes(PC1, PC2, label=OTU)) + 
  geom_point(alpha=0.5, size=3) +
  geom_text(size=3, vjust=0.5) +
  theme_bw() + 
  geom_hline(yintercept = 0, linetype=2) +  
  geom_vline(xintercept = 0, linetype=2) + 
  xlab(pc_xlab) + 
  ylab(pc_ylab) +
  theme(legend.position = "none") +
  coord_fixed(ratio=pc2/pc1) # Scale plot by variance explained

# Make compositional scree plot

layout(matrix(c(1,2),1,2, byrow=T), widths=c(6,4), heights=c(6,4))
par(mgp=c(2,0.5,0))
screeplot(f.pcx, type = "lines", main="Scree plot")
screeplot(f.pcx, type = "barplot", main="Scree plot")

```

### Test for differences between groups

The ADONIS approach was performed only on the species with more than two samples present in the dataset for greater robustness. The p-value of 0.001 indicates that at an alpha of 0.05, the grouping of bacteria by psyllid taxonomy is statistically significant. The R2 value 0.6332 indicated that approximately 63.3% of the microflora community groupings can be ascribed to the insect species (Table 4). 


Mantel test - 
See https://f1000research.com/articles/5-1492/v2 multitable techniques section

https://fukamilab.github.io/BIO202/06-C-matrix-comparison.html

Test for associations between 2 distance matrices

Distance matrices should be-

Phylogenetic distances between psyllids
Phylogenetic distances between host-plants
Geographic distances between collection locations

```{r adonis}

library(vegan)

gp.dist <- dist(gp.philr, method="euclidean")
metadata <- as(sample_data(ps2.philr), "data.frame")


adonis(gp.dist ~ psyllid_spp, method = "euclidean",
       data = metadata)

adonis(gp.dist ~ hostplant_spp, method = "euclidean",
       data = metadata)

#Pairwise permanova
tst<-adonis_pairwise(x=meta, dd=vegdist(OTUsSCM10, method = "euclidean"), group.var="Region_SKN")
tst$Adonis.tab

#Interacitons
adonis(gp.dist ~ psyllid_spp*hostplant_spp, method = "euclidean",
       data = metadata)

adonis(gp.dist ~ hostplant_spp*psyllid_spp,
       data = metadata)

#ano <- anosim(gp.dist, permutations=999)
```

This suggests that species significantly cluster, and so do hostplants. However when accounting for species, hostplants are not significant. Therefore it should be justified to redo the barchart merging by species 


### Merge replicates


```{r replicates}
# Merge replicates
ps.sppmerged <- ps3 %>%
    merge_samples(group = "psyllid_spp")

#This loses the sample metadata - Need to add it agian
samdf <- read.csv("sample_data/Sample_info.csv", header=TRUE) %>%
  filter(!duplicated(psyllid_spp)) %>%
  set_rownames(.$psyllid_spp) %>%
  dplyr::select(c("SampleID", "Sample.Name", "seqrun", "psyllid_spp", "psyllid_genus", "psyllid_family", "hostplant_spp","Collection","Collection.Date"))

sample_data(ps.sppmerged) <- samdf
ps4 <- filter_taxa(ps.sppmerged, function(x) mean(x) > 0, TRUE) #Drop missing taxa from table

```

### Species only beta

```{r beta plots}
ps4.coda <- ps4

#Rename taxa
taxa_names(ps4.coda) <- paste0("SV", seq(ntaxa(ps4.coda)),"-",tax_table(ps4.coda)[,6])

ps4.philr <- transform_sample_counts(ps4.coda, function(x) x+1)

ape::is.rooted(phy_tree(ps4.philr))
ape::is.binary.tree(phy_tree(ps4.philr))

phy_tree(ps4.philr) <- multi2di(phy_tree(ps4.philr))
phy_tree(ps4.philr) <- makeNodeLabel(phy_tree(ps4.philr), method="number", prefix='n')

#Transpose
otu.table <- otu_table(ps4.philr)
tree <- phy_tree(ps4.philr)
metadata <- as(sample_data(ps4.philr), "data.frame")
tax <- tax_table(ps4.philr)
ps4.philr <- philr(otu.table, tree,
                  part.weights='enorm.x.gm.counts',
                  ilr.weights='blw.sqrt')

gp.dist <- dist(ps4.philr, method="euclidean")


# perform a singular value decomposition of CLR
f.pcx <- prcomp(ps4.philr)
pcx <- f.pcx 

#Name balances

pcnames <-  sapply(rownames(pcx$rotation), function(x) name.balance(tree, tax, x))
pcnames <- make.unique(pcnames, sep = ".")

rownames(pcx$rotation) <- pcnames
#fviz_pca_biplot(pcx) 

#Extract biplot objects
pc_samp <- data.frame(psyllid_spp = rownames(pcx$x), pcx$x[, 1:2]) %>%
  left_join(samdf, by="psyllid_spp")
pc_otu <- data.frame(OTU = rownames(pcx$rotation), pcx$rotation[, 1:2])

# calculate percent variance explained for the axis labels
pc1 <- round(pcx$sdev[1]^2/sum(pcx$sdev^2),2)
pc2 <- round(pcx$sdev[2]^2/sum(pcx$sdev^2),2)
pc_xlab <- paste("PC1: ", pc1, sep="")
pc_ylab <- paste("PC2: ", pc2, sep="")

library(ggplot2)
gg.biplot <- ggplot(pc_samp, aes(PC1, PC2, label=psyllid_spp, colour=psyllid_spp)) + 
  geom_point(alpha=0.5, size=3) +
  #geom_text(size=3) +
  #geom_segment(data=pc_otu, aes(PC1, PC2, xend=0, yend=0), col="red") +
  #geom_text(data=pc_otu, aes(PC1, PC2, label=OTU), col="red") +
  geom_point(data=pc_otu,aes(PC1, PC2, label=OTU), col="red") +
  theme_bw() + 
  geom_hline(yintercept = 0, linetype=2) +  
  geom_vline(xintercept = 0, linetype=2) +
  xlab(pc_xlab) + 
  ylab(pc_ylab) +
  theme(legend.position = "none")# +
 # coord_fixed(ratio=pc2/pc1) # Scale plot by variance explained

#Plot just OTU loadings

gg.loadings <- ggplot(pc_otu, aes(PC1, PC2, label=OTU)) + 
  geom_point(alpha=0.5, size=3) +
  geom_text(size=3, vjust=0.5) +
  theme_bw() + 
  geom_hline(yintercept = 0, linetype=2) +  
  geom_vline(xintercept = 0, linetype=2) + 
  xlab(pc_xlab) + 
  ylab(pc_ylab) +
  theme(legend.position = "none") +
  coord_fixed(ratio=pc2/pc1) # Scale plot by variance explained

# Make compositional scree plot

layout(matrix(c(1,2),1,2, byrow=T), widths=c(6,4), heights=c(6,4))
par(mgp=c(2,0.5,0))
screeplot(f.pcx, type = "lines", main="Scree plot")
screeplot(f.pcx, type = "barplot", main="Scree plot")

#make compositional dendrogram
library(ggdendro)
library(dendextend)
hc <- hclust(gp.dist, method="ward.D2")
dend <- as.dendrogram(hc)

#Replace labels

# Rectangular lines
ddata <- dendro_data(dend, type = "rectangle")
gg.dend <- ggplot(segment(ddata)) + 
  geom_segment(aes(x = x, y = y, xend = xend, yend = yend))  + 
  scale_y_reverse(expand = c(0, 0)) +
  theme_void()+
  scale_x_discrete(expand=c(0.001,0.001))+
  coord_flip()

ps4_bar <- #subset_taxa(ps3, !Family == "Enterobacteriaceae") %>%
            ps4 %>%
  speedyseq::tax_glom(taxrank = "Order") %>%           # agglomerate at Order level
  transform_sample_counts(function(x) {x/sum(x)} ) %>% # Transform to rel. abundance
  speedyseq::psmelt() %>%
  #mutate(Family = case_when(
  #  Abundance >= 0.01 ~ Genus, # Change this to whatever taxrank we want
  #  Abundance < 0.01 ~ "NA"
  #  )) %>%
  #mutate(plot_level = case_when(
  #  Family == "Enterobacteriaceae" | Genus == "Candidatus_Carsonella" ~ paste0("G-",Genus),
  #  TRUE  ~ paste0("P-", Phylum),
  #  )) %>%
  filter(Abundance > 0.01) %>% # Could instead mutate this to just be "Low abundance"
    mutate(psyllid_spp = factor(psyllid_spp, levels=labels(dend)))

library(RColorBrewer)
col <- colorRampPalette(brewer.pal(11, "Spectral"))(26)

gg.bar <- ggplot(ps4_bar, aes(x = psyllid_spp, y = Abundance, fill = Order)) + 
  geom_bar(stat = "identity", width = 0.8) +
  theme_minimal()+
  theme(axis.title = element_blank(),
        axis.ticks = element_blank(),
        legend.position = "right",
        plot.margin=unit(c(-2,-1,10,0),unit="cm")) +
  scale_x_discrete(expand=c(0,0),position="top")+
  scale_y_discrete(expand=c(0,0))+
  scale_fill_manual(values=col) +
  guides(fill=guide_legend(ncol=1)) +
  coord_flip() 

#plot together

Fig2 <- gg.dend + gg.bar + plot_layout(ncol = 2, widths = c(1,3)) + plot_annotation(title="Microbial diversity of New Zealand psyllids, taxa >0.01", subtitle="Merged by species, PhilR transformation, Ward d2 Heirarchial clustering", tag_levels="A")

```

## Random forest

## Mantel test

RF Distane

Congruencies between host phylogenies and skin microbiota dendrograms were quantified by calculating normalized Robinson–Foulds (89) and
normalized matching-cluster scores.
# Cophylogenetic analyses


## Fit neutral model


Cluster at a rate that approximates genus (95%?) Before fititng neutral model
Loop through those that are above the predicitons, doing a mantel test for each

Specifically, points above the prediction represent taxa that are found more frequently than expected, suggesting that they are actively being maintained and selected for by the host, while points found below the prediction represent taxa found less frequently than expected, suggesting that they are either selected against by the host or are especially dispersal limited. 


```{r}
library(reltools)
library(minpack.lm)
library(Hmisc)

ps.neutral <- speedyseq::tax_glom(ps2, taxrank="Genus")

ps.neutral <- tip_glom(ps2, h=0.2)

spp <- otu_table(ps.neutral)@.Data
spp.out <- fit_sncm(spp, pool=spp, taxon=data.frame(tax_table(ps.neutral)))


library(ggrepel)
gg.neutral <- ggplot(data = spp.out$predictions) + 
  geom_point(aes(x = log(p), y = freq, fill = fit_class),
        shape = 21, color = "black", size = 2, alpha = 0.75) +
  scale_fill_manual(name = "Prediction", 
        values = c(`Above prediction` = "cyan4", 
            `As predicted` = "blue", `Below prediction` = "goldenrod", 
            `NA` = "white"), breaks = c("Above prediction", 
            "As predicted", "Below prediction", 
            "NA"), labels = c(paste0("Above prediction (", 
            round((df[1, 2]/spp.out$fitstats$Richness) * 
              100, 1), "%)"), paste0("As predicted (", 
            round((df[2, 2]/spp.out$fitstats$Richness) * 
              100, 1), "%)"), paste0("Below Prediction (", 
            round((df[3, 2]/spp.out$fitstats$Richness) * 
              100, 1), "%)"), paste0("NA (", 
            df[4, 2], ")"))) +
  geom_line(aes(x = log(p), y = freq.pred), color = "blue") + 
  geom_line(aes(x = log(p), y = pred.lwr), color = "blue", linetype = "dashed") + 
  geom_line(aes(x = log(p), y = pred.upr), color = "blue", linetype = "dashed") +
  theme_bw() +
  geom_label_repel(data = (spp.out$predictions %>% filter(fit_class == "Above prediction") %>% filter(freq > 0.5)), aes(x = log(p), y = freq,  label=Genus))+
  xlab("log(Mean Relative Abundance)") +
  ylab("Frequency") +
  annotate("text", x = mean(log(spp.out$predictions$p), na.rm = TRUE),
           y = 0.95, size = 5, label =  paste("r^2 ==", round(spp.out$fitstats$Rsqr, 4)), parse = TRUE) +  
  annotate("text", x = mean(log(spp.out$predictions$p), na.rm = TRUE),
           y = 0.9, size = 5, label =  paste("m ==", round(spp.out$fitstats$m,  4)), parse = TRUE)


```


## Minimum abundance threshold

Maybe this should be done just for carsonella tree

These samples were sequenced using combinatorial indexes. Therefore this data will contain index switching. We therefore need to select an optimal filtering threshold to remove switched taxa, but not real taxa. We will optimise our filtering threshold by relying on assumption that all psyllid species should contain only one (or few very closely related ASVs) of Carsonella.

```{r thresholds}
#Flag top abundance carsonella
top_carson <-  ps2 %>%
  transform_sample_counts(function (x) x/sum(x)) %>%
  speedyseq::psmelt() %>%
  filter(Genus=="Candidatus_Carsonella") %>%
  group_by(Sample) %>%
  top_n(1, wt=Abundance) %>%
  mutate(top = TRUE)  %>%
  filter(Abundance > 0)
  
#Flag lower abundance carsonella
carson <-  ps2 %>%
  transform_sample_counts(function (x) x/sum(x)) %>%
  speedyseq::psmelt() %>%
  filter(Genus=="Candidatus_Carsonella") %>%
  left_join(top_carson) %>%
  mutate(top = case_when(
    is.na(top) ~ FALSE,
    !is.na(top) ~ top
  ))

## THis needs to be changed - things should be flagged as switched when less than 100* the top!, or combine both - ie 

carson <- carson %>%
  left_join(carson %>%
    filter(Abundance > 0) %>%
    dplyr::select(OTU, top, seqrun) %>%
    unique() %>%
    group_by(OTU, seqrun) %>%
    add_tally() %>%
    mutate(switched = case_when(
      n>1 & top== FALSE ~ TRUE,
      n>1 & top== TRUE ~ FALSE,
      n==1 ~ FALSE,
    )) %>%
  dplyr::select(-n)
  )

## Plot true and false carsonellas by run - this shows may need to filter seperately by run, as seqrun2 has much higher than others.
gg.switch <- carson %>% 
  group_by(seqrun, switched) %>%
  filter(!is.na(switched)) %>%
  filter(Abundance > 0) %>%
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>%
  ggplot(aes(x=seqrun, y=freq, group=switched, fill=switched)) +
  geom_bar(stat="identity")


#to check if index switching could explain the multiple OTU's check if top=FALSE carsonella exist as top in another sample in the same run

thresholds <- seq(0,0.05,0.0001)
out <- vector("list", length=3)
for (r in 1:3) {
  df <- data.frame(thresh = thresholds, TP= thresholds, FP = thresholds, seqrun = r)
  for(i in 1:length(thresholds)){
    filt <- carson %>%
      filter(seqrun==r) %>%
      filter(Abundance > thresholds[i]) %>%
      group_by(top) %>%
      summarise(sum=n())
    df$FP[i] <- filt$sum[1]
    df$TP[i] <- filt$sum[2]
  }
  out[[r]] <- df
}

gg.filt <- out %>%
  bind_rows() %>%
  gather(key=type, value=n, -thresh, -seqrun) %>%
  ggplot(aes(x=thresh, y=n, fill=type)) + 
  geom_density(stat="identity", alpha=0.5) + 
  scale_x_continuous(breaks=seq(0,0.05,0.001)) +
  facet_grid(~seqrun) +
  theme(axis.text.x = element_text(angle=45,hjust=1)) + 
  geom_vline(xintercept = 0.0035)+ 
  geom_vline(xintercept = 0.001)

print(gg.filt)

## Filter run 2 
run2_ps <- ps2 %>% 
  subset_samples(seqrun==2)

run2_pass <- run2_ps %>%
    transform_sample_counts(function (x) x/sum(x)) %>%  # Convert to proportions
    transform_sample_counts(function (x) (x > 0.001) * 1)

newotu1 <- otu_table(run2_ps) * otu_table(run2_pass)

run2_newps <- run2_ps
otu_table(run2_newps) <- otu_table(newotu1, taxa_are_rows = FALSE) 

#Filter run 1 and 3 
  
run13_ps <- ps2 %>%
    subset_samples(!seqrun == 2)
                   
run13_pass <- run13_ps %>%
    transform_sample_counts(function (x) x/sum(x)) %>%  # Convert to proportions
    transform_sample_counts(function (x) (x > 0.0005) * 1)

newotu2  <- otu_table(run13_ps) * otu_table(run13_pass)

run13_newps <- run13_ps
otu_table(run13_newps) <- otu_table(newotu2, taxa_are_rows = FALSE) 

# Create new phyloseq and drop missing taxa
ps3 <- merge_phyloseq(run2_newps, run13_newps) %>%
  filter_taxa(function(x) mean(x) > 0, TRUE) #Drop missing taxa from table
ps3 <- prune_samples(sample_sums(ps3) >0 , ps3) # Drop empty samples

#Count number of overall taxa pre and post filtering
print(paste(ntaxa(ps2) - ntaxa(ps3), " taxa Dropped when using filtering threshold of: ", 0.0035, " for run 2 and ", 0.001, "for run 1 and 3"))

# Count number of carsonella OTU's per sample pre and post filtering
n_carson <- speedyseq::psmelt(ps2) %>% 
  filter(Genus == "Candidatus_Carsonella") %>%
  filter(Abundance > 0) %>%
  dplyr::select(Sample.Name, OTU) %>%
  group_by(Sample.Name) %>%
  add_tally() %>%
  dplyr::select(-OTU) %>%
  unique() %>%
  mutate(type = "pre") %>%
  bind_rows(.,speedyseq::psmelt(ps3) %>% 
  filter(Genus == "Candidatus_Carsonella") %>%
  filter(Abundance > 0) %>%
  dplyr::select(Sample.Name, OTU) %>%
  group_by(Sample.Name) %>%
  add_tally() %>%
  dplyr::select(-OTU) %>%
  unique() %>%
  mutate(type = "post"))

gg.ncarson <- ggplot(n_carson, aes(x=reorder(Sample.Name, -n), y=n)) + 
  geom_bar(stat="identity") +
  facet_grid(~type) + 
  xlab("Sample.Name") +
  ylab("Number of carsonella OTU's per sample") +
  theme(axis.text.x = element_text(angle=90, hjust = 1, vjust=0))

print(gg.ncarson)

#check if any samples dont have carsonella
table(!n_carson$Sample.Name %in% speedyseq::psmelt(ps2)$Sample.Name)

## Get the name of taxa that dont have carsonella after filtering

```

```{r subsetting}
library(plotly)

#filter threshold to ge
#ps2.carson <- transform_sample_counts(ps2, fun = proportions, thresh=0.0045)

#ps2.carson <- subset_taxa(ps2.carson, Genus == "Candidatus_Carsonella")
#ps2.carson <- filter_taxa(ps2.carson, function(x) mean(x) > 0, TRUE) #Drop missing taxa from table
#ps2.carson <- prune_samples(sample_sums(ps2.carson)>0, ps2.carson) # Drop empty samples

library(RColorBrewer)
col <- colorRampPalette(brewer.pal(11, "Spectral"))(74)


ps2.carson <- subset_taxa(ps2, Species == "Candidatus Carsonella")
gg.carson <- plot_tree(ps2.carson, ladderize="left",  color="psyllid_spp") +   theme(legend.position = "none") + #
    scale_colour_manual(values=col) + scale_fill_manual(values=col)
  ggtitle("Carsonella 16S gene tree")
#gg.ncarson
  
## Aquabacterium
gg.tree <- plot_tree(subset_taxa(ps2, Species == "Sulfuritalea"), ladderize="left",  color="psyllid_spp") +   theme(legend.position = "none") + #
    scale_colour_manual(values=col) + scale_fill_manual(values=col)
  ggtitle("Carsonella 16S gene tree")
#gg.ncarson

#Write out fasta

carson_out <- speedyseq::psmelt(ps3.carson) %>%
  filter(Abundance > 0) %>%
  select(OTU, Sample.Name, psyllid_spp, Species) %>%
  group_by(OTU, Species) %>%
  summarize(samples = paste(Sample.Name, collapse=";"),
            psyllid_spp = paste(unique(psyllid_spp), collapse=";")
            ) %>%
  rownames_to_column() %>%
  unite(seqname, c("Species","rowname","psyllid_spp","samples"), sep="|")

carson_fasta <- DNAStringSet(carson_out$OTU)
names(carson_fasta) <- carson_out$seqname

writeXStringSet(carson_fasta, "carsonella_seqs.fa")


## S-Symbionts
ps3.carson <- subset_taxa(ps3, Family == "Enterobacteriaceae")
taxa_names(ps3.carson) <- paste0("SV", seq(ntaxa(ps3.carson)),"-",tax_table(ps3.carson)[,7])

gg.entero <- plot_tree(ps3.carson, ladderize="left",  color="psyllid_spp", label.tips="taxa_names") +   theme(legend.position = "none") +     #scale_colour_manual(values=col) +
  ggtitle("Enterobacidae 16S gene tree")

#, label.tips="psyllid_spp

```

## Tanglegram

```{r tanglegram}
#Tanglegram
library(dendextend)
dend_list <- dendlist(as.dendrogram (hc), as.dendrogram (gp.hc))

dend_list <- untangle(dend_list, method="step1side")
tanglegram(dend_list)


dend_diff(dend_list)

#Look at adonis  

library(vegan)

```


# Core microbiome

## Subset to core microbiome

## Functional profiling

PICRUST2


```{r session-info}
# Display current R session information
sessionInfo()
```
